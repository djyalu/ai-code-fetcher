import { AIModel } from '@/types/chat';

export const MODELS: AIModel[] = [
  {
    id: 'gpt-4o',
    name: 'GPT-4o',
    provider: 'openai',
    description: 'OpenAIì˜ ìµœì‹  ë©€í‹°ëª¨ë‹¬ ëª¨ë¸',
    inputPrice: 2.5,
    outputPrice: 10,
    contextWindow: 128000,
    color: '#10a37f',
  },
  {
    id: 'gpt-4o-mini',
    name: 'GPT-4o Mini',
    provider: 'openai',
    description: 'ë¹ ë¥´ê³  ê²½ì œì ì¸ GPT-4o ë²„ì „',
    inputPrice: 0.15,
    outputPrice: 0.6,
    contextWindow: 128000,
    color: '#10a37f',
  },
  {
    id: 'claude-3-5-sonnet',
    name: 'Claude 3.5 Sonnet',
    provider: 'anthropic',
    description: 'Anthropicì˜ ê°€ìž¥ ì§€ëŠ¥ì ì¸ ëª¨ë¸',
    inputPrice: 3,
    outputPrice: 15,
    contextWindow: 200000,
    color: '#cc785c',
  },
  {
    id: 'claude-3-5-haiku',
    name: 'Claude 3.5 Haiku',
    provider: 'anthropic',
    description: 'ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ Claude ëª¨ë¸',
    inputPrice: 0.25,
    outputPrice: 1.25,
    contextWindow: 200000,
    color: '#cc785c',
  },
  {
    id: 'gemini-2.0-flash',
    name: 'Gemini 2.0 Flash',
    provider: 'google',
    description: 'Googleì˜ ìµœì‹  ê³ ì† ëª¨ë¸',
    inputPrice: 0.1,
    outputPrice: 0.4,
    contextWindow: 1048576,
    color: '#4285f4',
  },
  {
    id: 'gemini-1.5-pro',
    name: 'Gemini 1.5 Pro',
    provider: 'google',
    description: 'Googleì˜ ê³ ì„±ëŠ¥ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸',
    inputPrice: 1.25,
    outputPrice: 5,
    contextWindow: 2097152,
    color: '#4285f4',
  },
  {
    id: 'deepseek-chat',
    name: 'DeepSeek V3',
    provider: 'deepseek',
    description: 'ì¤‘êµ­ì˜ ê°•ë ¥í•œ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸',
    inputPrice: 0.14,
    outputPrice: 0.28,
    contextWindow: 64000,
    color: '#5865f2',
  },
  // Free Research Models
  {
    id: 'google/gemini-2.0-flash-exp:free',
    name: 'Gemini 2.0 Flash (Free)',
    provider: 'google',
    description: 'êµ¬ê¸€ ìµœì‹  ëª¨ë¸. ê¸´ ë¬¸ë§¥(1M) ì²˜ë¦¬ì™€ ë¹ ë¥¸ ì†ë„ë¥¼ ìžëž‘í•˜ëŠ” ê°€ì„±ë¹„ ìµœê³ ì˜ ëª¨ë¸.',
    inputPrice: 0,
    outputPrice: 0,
    contextWindow: 1048576,
    color: '#34a853',
  },
  {
    id: 'meta-llama/llama-3.3-70b-instruct:free',
    name: 'Llama 3.3 70B (Free)',
    provider: 'meta',
    description: 'ë©”íƒ€ì˜ ê°•ë ¥í•œ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸. ë²”ìš©ì ì¸ ìž‘ì—…ì—ì„œ ë§¤ìš° ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.',
    inputPrice: 0,
    outputPrice: 0,
    contextWindow: 128000,
    color: '#0668E1',
  },
  {
    id: 'deepseek/deepseek-r1-0528:free',
    name: 'DeepSeek R1 (Free)',
    provider: 'deepseek',
    description: 'DeepSeekì˜ ìµœì‹  ì¶”ë¡  ëª¨ë¸. R1 ì•„í‚¤í…ì²˜ë¥¼ ì ìš©í•˜ì—¬ ë…¼ë¦¬ì  ì‚¬ê³  ëŠ¥ë ¥ì´ ê°•í™”ë˜ì—ˆìŠµë‹ˆë‹¤.',
    inputPrice: 0,
    outputPrice: 0,
    contextWindow: 64000,
    color: '#5865f2',
  },
  {
    id: 'nvidia/nemotron-3-nano-30b-a3b:free',
    name: 'Nemotron 3 30B (Free)',
    provider: 'nvidia',
    description: 'ì—”ë¹„ë””ì•„ì˜ ì •ë°€ ëª¨ë¸. RAG ì‹œìŠ¤í…œê³¼ ë°ì´í„° ì¶”ì¶œ ìž‘ì—…ì— ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ìž…ë‹ˆë‹¤.',
    inputPrice: 0,
    outputPrice: 0,
    contextWindow: 131072,
    color: '#76b900',
  },
  {
    id: 'mistralai/devstral-2512:free',
    name: 'Mistral Devstral (Free)',
    provider: 'mistral',
    description: 'Mistralì˜ ê°œë°œìžìš© ì‹¤í—˜ ëª¨ë¸. ì½”ë”© ë° ê¸°ìˆ ì ì¸ ìž‘ì—…ì— ì í•©í•©ë‹ˆë‹¤.',
    inputPrice: 0,
    outputPrice: 0,
    contextWindow: 32000,
    color: '#fd6f00',
  },
  {
    id: 'arcee-ai/trinity-mini:free',
    name: 'Arcee Trinity Mini (Free)',
    provider: 'arcee',
    description: 'Arcee AIì˜ ì†Œí˜• ê³ ì„±ëŠ¥ ëª¨ë¸. íŠ¹í™”ëœ ë„ë©”ì¸ ì§€ì‹ê³¼ ë¹ ë¥¸ ì¶”ë¡  ì†ë„ê°€ íŠ¹ì§•ìž…ë‹ˆë‹¤.',
    inputPrice: 0,
    outputPrice: 0,
    contextWindow: 32000,
    color: '#8b5cf6',
  },
  {
    id: 'nvidia/nemotron-nano-9b-v2:free',
    name: 'Nemotron Nano 9B (Free)',
    provider: 'nvidia',
    description: 'ì—”ë¹„ë””ì•„ì˜ ì´ˆê²½ëŸ‰ ëª¨ë¸. ë§¤ìš° ë¹ ë¥¸ ì‘ë‹µ ì†ë„ë¡œ ê°„ë‹¨í•œ ì§ˆì˜ì‘ë‹µì— ì í•©í•©ë‹ˆë‹¤.',
    inputPrice: 0,
    outputPrice: 0,
    contextWindow: 32000,
    color: '#76b900',
  },
  {
    id: 'openai/gpt-oss-120b:free',
    name: 'GPT-OSS 120B (Free)',
    provider: 'openai',
    description: 'ì˜¤í”ˆì†ŒìŠ¤ ê¸°ë°˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸. GPT ê³„ì—´ì˜ ì„±ëŠ¥ì„ ë¬´ë£Œë¡œ ì²´í—˜í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.',
    inputPrice: 0,
    outputPrice: 0,
    contextWindow: 8192,
    color: '#10a37f',
  },
  {
    id: 'mistralai/mistral-small-3.1-24b-instruct:free',
    name: 'Mistral Small 3.1 (Free)',
    provider: 'mistral',
    description: 'Mistralì˜ íš¨ìœ¨ì ì¸ ì¤‘í˜• ëª¨ë¸. ì§€ì‹œ ì´í–‰ ëŠ¥ë ¥ê³¼ ì‘ë‹µ í’ˆì§ˆì˜ ê· í˜•ì´ ì¢‹ìŠµë‹ˆë‹¤.',
    inputPrice: 0,
    outputPrice: 0,
    contextWindow: 32000,
    color: '#fd6f00',
  },
  {
    id: 'google/gemma-3-27b-it:free',
    name: 'Gemma 3 27B (Free)',
    provider: 'google',
    description: 'êµ¬ê¸€ì˜ ì˜¤í”ˆ ì›¨ì´íŠ¸ ëª¨ë¸. 27B íŒŒë¼ë¯¸í„°ë¡œ ë›°ì–´ë‚œ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.',
    inputPrice: 0,
    outputPrice: 0,
    contextWindow: 131072,
    color: '#4285f4',
  },
];

export const SYNTHESIS_MODELS = ['google/gemma-3-27b-it:free', 'google/gemini-2.0-flash-exp:free'];

export const DEFAULT_SYSTEM_PROMPT = `You are a helpful AI assistant. Respond concisely and accurately.`;

export const SYNTHESIS_PROMPT = `You are an expert synthesizer and data analyst. You will receive responses from multiple AI models to the same user question.
Your task is to create a comprehensive synthesis that adds meta-analysis of the model responses.

Structure your response as follows:
1. âœ¨ **Master Synthesis**: A comprehensive final answer that resolves contradictions and provides the most accurate conclusion.
2. ðŸ” **Model Comparison Analysis**:
   - **Similarities (ê³µí†µì )**: Key points that all or most models agreed upon.
   - **Differences (ì°¨ì´ì )**: Unique insights or different perspectives provided by specific models.
3. âš–ï¸ **Conflict & Ratio (ìƒì¶© ì •ë³´ ë° ë¹„ìœ¨)**: If models provide conflicting information, explicitly state the ratio (e.g., "3 out of 5 models (60%) suggest X, while 2 models (40%) suggest Y").
4. ðŸ’¾ **Key Takeaways**: A quick summary of the most critical facts identified across the orchestration.

Ensure the final result is easy to read using Markdown tables, lists, and bold text. The language of the response should match the language of the user's question (default to Korean if unsure).`;

export const getModelById = (id: string): AIModel | undefined => {
  return MODELS.find(model => model.id === id);
};

export const getModelsByProvider = (provider: string): AIModel[] => {
  return MODELS.filter(model => model.provider === provider);
};
